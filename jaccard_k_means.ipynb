{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 20.258369858348196\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Verifying the user input arguments\n",
    "\"\"\"\n",
    "numOfClusters = 6\n",
    "initialSeedsFile = \"data/InitialSeeds.txt\"\n",
    "tweetsDataFile = \"data/Tweets_Negative_CC.xlsx\"\n",
    "outputFile = \"data/tweets-k-means-output-2.txt\"\n",
    "\n",
    "\"\"\"\n",
    "Initializing the centroid tweet Ids in to a dictionary\n",
    "\"\"\"\n",
    "tweetCentroidIds = {}\n",
    "with open(initialSeedsFile) as tweet_centroid:\n",
    "    centroids = tweet_centroid.read().rsplit(\",\\n\")\n",
    "    centroids = [int(i) for i in centroids]\n",
    "    if len(centroids) == numOfClusters:\n",
    "        for id in range(0, numOfClusters):\n",
    "            tweetCentroidIds[id] = centroids[id]\n",
    "    else:\n",
    "        print (\"[Error]: Initial seed file contains values not equal to the clusters entered\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "\"Function to read json file and store tweet id and its text in a dictionary\"\n",
    "def readJson(tweetJson):\n",
    "    for line in tweetJson:\n",
    "        readTweets = json.loads(line)\n",
    "        tweetsJsonData[str(readTweets[\"id\"])] = readTweets[\"text\"]\n",
    "\n",
    "\"\"\"\n",
    "Initializing a dictionary with key as tweet Id and values with corresponding text/tweet\n",
    "\"\"\"\n",
    "tweetsJsonData = {}\n",
    "with open(tweetsDataFile) as tweetJson:\n",
    "    actual_data=pd.read_excel(tweetsDataFile,header=None)\n",
    "    tweetsJsonData=actual_data[0].to_dict()\n",
    "    del tweetsJsonData[0]\n",
    "\n",
    "\"\"\"\n",
    "This function return the count of unique words in each tweet\n",
    "\"\"\"\n",
    "def tweetWords(wordsList):\n",
    "    counts = {}\n",
    "    for word in wordsList:\n",
    "        if word in counts:\n",
    "            counts[word] = counts[word] + 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    return counts\n",
    "\n",
    "\"\"\"\n",
    "Function to check number of words of one tweet matches another tweet\n",
    "\"\"\"\n",
    "def tweetIntersection(tweet1, tweet2):\n",
    "    result = 0\n",
    "    for word in tweet1:\n",
    "        while tweet1[word] != 0 and word in tweet2:\n",
    "            if word in tweet2:\n",
    "                tweet2[word] = tweet2[word] - 1\n",
    "                tweet1[word] = tweet1[word] - 1\n",
    "                if tweet2[word] == 0:\n",
    "                    tweet2.pop(word, None)\n",
    "                result += 1\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Function to word count of tweets in comparison, counting the matching words only once\n",
    "\"\"\"\n",
    "def tweetUnion(tweet1, tweet2):\n",
    "    result = 0\n",
    "    for word in tweet1:\n",
    "        if word in tweet2:\n",
    "            result = result + max(tweet1[word], tweet2[word])\n",
    "            tweet2.pop(word, None)\n",
    "        else:\n",
    "            result = result + tweet1[word]\n",
    "    for word in tweet2:\n",
    "        result = result + tweet2[word]\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Function to calculate whether two tweets are similar or not\n",
    "If returned value is small both tweets have more similarities or else they are less similar\n",
    "\"\"\"\n",
    "def jaccard_distance(tweet_a, tweet_b):\n",
    "    tweet1Words = tweetWords(tweet_a)           #tweet_a.split()\n",
    "    tweet2Words = tweetWords(tweet_b)           #tweet_b.split()\n",
    "    tweetWordsUnion = tweetUnion(dict(tweet1Words), dict(tweet2Words))\n",
    "    tweetWordsIntersect = tweetIntersection(dict(tweet1Words), dict(tweet2Words))\n",
    "    return 1.0 - tweetWordsIntersect*1.0/tweetWordsUnion\n",
    "\n",
    "\"\"\"\n",
    "Function to assign tweets to a cluster\n",
    "\"\"\"\n",
    "def formClusters(tweetCentroidIds, tweetsJsonData):\n",
    "    clusters = {}\n",
    "    for index in range(len(tweetCentroidIds)):\n",
    "        clusters[index] = []\n",
    "    for tweet in tweetsJsonData:\n",
    "        minJaccardDist = 1\n",
    "        cluster = 0\n",
    "        for centroidId in tweetCentroidIds:\n",
    "            tweetCentroidDist = 1\n",
    "            tweetCentroidDist = jaccard_distance(tweetsJsonData[tweetCentroidIds[centroidId]], tweetsJsonData[tweet])\n",
    "            if tweetCentroidDist < minJaccardDist:\n",
    "                minJaccardDist = tweetCentroidDist\n",
    "                cluster = centroidId\n",
    "        clusters[cluster].append(tweet)\n",
    "    return clusters\n",
    "\n",
    "\"\"\"\n",
    "Function to recalculate centroid for a cluster taking all the tweets in account\n",
    "\"\"\"\n",
    "def recalculateCentroid(cluster, tweet_data):\n",
    "    centroidId = cluster[0]\n",
    "    min_distance = 1\n",
    "    for tweet in cluster:\n",
    "        total_distance = 0\n",
    "        for other_tweet in cluster:\n",
    "            total_distance = total_distance + jaccard_distance(tweet_data[tweet], tweet_data[other_tweet])\n",
    "        mean_distance = total_distance * 1.0 / len(cluster)\n",
    "        if mean_distance < min_distance:\n",
    "            min_distance = mean_distance\n",
    "            centroidId = tweet\n",
    "    return centroidId\n",
    "\n",
    "\"\"\"\n",
    "Function to calculate the squared sum of errors(SSE)\n",
    "\"\"\"\n",
    "def sse(clusters, centroid_values, tweet_data):\n",
    "    result = 0\n",
    "    for cluster in clusters:\n",
    "        for tweet in clusters[cluster]:\n",
    "            result += math.pow(jaccard_distance(tweet_data[tweet], tweet_data[centroid_values[cluster]]),2)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "K-means clustering until centroid remains same\n",
    "\"\"\"\n",
    "updateCentroidIds = {}\n",
    "while True:\n",
    "    clusters = formClusters(tweetCentroidIds, tweetsJsonData)\n",
    "    for cluster in clusters:\n",
    "        updateCentroidIds[cluster] = recalculateCentroid(clusters[cluster], tweetsJsonData)\n",
    "    if updateCentroidIds == tweetCentroidIds:\n",
    "        sseValue = str(sse(clusters, updateCentroidIds, tweetsJsonData))\n",
    "        print (\"SSE: \" + sseValue)\n",
    "        break\n",
    "    else:\n",
    "        tweetCentroidIds = updateCentroidIds\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Writing the sse value and clusters in to the output file\n",
    "\"\"\"\n",
    "fileToOutput = open(outputFile, 'w')\n",
    "fileToOutput.write(\"SSE Value: \")\n",
    "fileToOutput.write(sseValue)\n",
    "fileToOutput.write(\"\\n\\nClusters:\\n\\n\")\n",
    "for cluster in clusters:\n",
    "    fileToOutput.write(str(cluster))\n",
    "    fileToOutput.write(\"\\t\")\n",
    "    for tweet in clusters[cluster]:\n",
    "        fileToOutput.write(str(tweet))\n",
    "        fileToOutput.write(\", \")\n",
    "    fileToOutput.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
