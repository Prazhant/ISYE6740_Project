{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b5a73bdd3d97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-b5a73bdd3d97>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m#         print(\"centroids dict\",centroids_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m#         print(\"tweets dict\",tweets_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mnew_centroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_new_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b5a73bdd3d97>\u001b[0m in \u001b[0;36mform_clusters\u001b[0;34m(tweets_dict, centroid_dict)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mclusterId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcentroid_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mjaccardDistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcentroid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccardDistance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mmin_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccardDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Apr  9 23:05:54 2018\n",
    "\n",
    "@author: patil\n",
    "\"\"\"\n",
    "\n",
    "import json,sys\n",
    "\n",
    "# Reading json file in a dictionary\n",
    "def getTweets(tweetsJsonFile):\n",
    "    actual_data=pd.read_excel(tweetsJsonFile,header=None)\n",
    "    print(type(actual_data[0]))\n",
    "    return actual_data[0].to_dict()\n",
    "\n",
    "\n",
    "def getCentroids(initialSeedsFile):\n",
    "    with open(initialSeedsFile) as centroid_tweet_file:\n",
    "        return centroid_tweet_file.read().rsplit(\",\\n\")\n",
    "\n",
    "\n",
    "def getCentroidsDict(centroids):\n",
    "    centroids_dict = {}\n",
    "    numOfClusters = len(centroids)\n",
    "    for idx in range(0, numOfClusters):\n",
    "        centroids_dict[idx] = centroids[idx]\n",
    "    return centroids_dict\n",
    "\n",
    "def countWords(list_of_words):\n",
    "    counts_dict = {}\n",
    "    for word in list_of_words:\n",
    "        if word in counts_dict:\n",
    "            counts_dict[word] = counts_dict[word] + 1\n",
    "        else:\n",
    "            counts_dict[word] = 1\n",
    "    return counts_dict\n",
    "\n",
    "def intersection(tweetdata_one, tweetdata_two):\n",
    "    result_intesection = 0\n",
    "    for word in tweetdata_one:\n",
    "        while tweetdata_one[word] != 0 and word in tweetdata_two:\n",
    "            if word in tweetdata_two:\n",
    "                tweetdata_two[word] = tweetdata_two[word] - 1\n",
    "                tweetdata_one[word] = tweetdata_one[word] - 1\n",
    "                if tweetdata_two[word] == 0:\n",
    "                    tweetdata_two.pop(word, None)\n",
    "                result_intesection += 1\n",
    "    return result_intesection\n",
    "\n",
    "def union(tweetdata_one, tweetdata_two):\n",
    "    result_union = 0\n",
    "    for word in tweetdata_one:\n",
    "        if word in tweetdata_two:\n",
    "            result_union = result_union + max(tweetdata_one[word], tweetdata_two[word])\n",
    "            tweetdata_two.pop(word, None)\n",
    "        else:\n",
    "            result_union = result_union + tweetdata_one[word]\n",
    "    for word in tweetdata_two:\n",
    "        result_union = result_union + tweetdata_two[word]\n",
    "    return result_union\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def jaccard_distance(tweetDataOne, tweetDataTwo):\n",
    "    tweetDataOne_count = countWords(tweetDataOne)\n",
    "    tweetDataTwo_count = countWords(tweetDataTwo)\n",
    "    tweetdata_union = union(dict(tweetDataOne_count), dict(tweetDataTwo_count))\n",
    "    tweetdata_intersect = intersection(dict(tweetDataOne_count), dict(tweetDataTwo_count))\n",
    "    return 1.0 - tweetdata_intersect * 1.0 / tweetdata_union\n",
    "\n",
    "\n",
    "def form_clusters(tweets_dict, centroid_dict):\n",
    "    clusters = {}\n",
    "    for i in range(len(centroid_dict)):                 # Initialize clusters\n",
    "        clusters[i] = []\n",
    "\n",
    "    for tweet_id in tweets_dict:\n",
    "        min_distance = 1\n",
    "        clusterId = 0\n",
    "        for index in centroid_dict:\n",
    "            jaccardDistance = jaccard_distance(tweets_dict[centroid_dict[index]], tweets_dict[tweet_id], )\n",
    "            if(jaccardDistance < min_distance):\n",
    "                min_distance = jaccardDistance\n",
    "                clusterId = index\n",
    "        clusters[clusterId].append(tweet_id)\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def find_new_centroids(cluster, tweets):\n",
    "    min_distance = 1\n",
    "    min_cluster_id = cluster[0]\n",
    "    for cluster_tweet_id in cluster:\n",
    "        distance = 0\n",
    "        for other_cluster_tweetid in cluster:\n",
    "            distance = distance + jaccard_distance(tweets[cluster_tweet_id], tweets[other_cluster_tweetid] )\n",
    "        mean = distance/len(cluster)\n",
    "        if mean < min_distance:\n",
    "            min_distance = mean\n",
    "            min_cluster_id = cluster_tweet_id\n",
    "    return min_cluster_id\n",
    "\n",
    "def sum_squared_error(clusters, centroids, tweet_data):\n",
    "    sse = 0\n",
    "    for cluster in clusters:\n",
    "        for tweet_id in clusters[cluster]:\n",
    "            sse += jaccard_distance(tweet_data[tweet_id], tweet_data[centroids[cluster]]) ** 2\n",
    "    return sse\n",
    "\n",
    "def main():\n",
    "    # number_of_clusters = 25\n",
    "    # initial_seeds_file = \"InitialSeeds.txt\"\n",
    "    # tweets_data_file = \"Tweets.json\"\n",
    "    # outputfile = \"out.txt\"\n",
    "\n",
    "    \n",
    "    number_of_clusters = 6\n",
    "    initial_seeds_file = \"data/InitialSeeds.txt\"\n",
    "    tweets_data_file = \"data/Tweets_Negative_CC.xlsx\"\n",
    "    outputfile = \"data/tweets-k-means-output.txt\"\n",
    "    \n",
    "    \n",
    "    tweets_dict = getTweets(tweets_data_file)\n",
    "    #print(\"Tweets Dictionary: \", tweets_dict)\n",
    "    centroids = getCentroids(initial_seeds_file)\n",
    "    #print(\"Centroids: \", centroids)\n",
    "\n",
    "    if len(centroids) != number_of_clusters:\n",
    "        print(\"Mismatch between number of values in Initial seed file and number of clusters entered\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        new_centroids = []\n",
    "        centroids_dict = getCentroidsDict(centroids)\n",
    "        print(\"centroids dict\",centroids_dict)\n",
    "        print(\"tweets dict\",tweets_dict)\n",
    "        clusters = form_clusters(tweets_dict, centroids_dict)\n",
    "        for cluster in clusters:\n",
    "            new_centroids.append(find_new_centroids(clusters[cluster], tweets_dict))\n",
    "        if new_centroids == centroids:\n",
    "            break\n",
    "        else:\n",
    "            centroids = new_centroids\n",
    "\n",
    "    output_result_file = open(outputfile, 'w')\n",
    "    output_result_file.write(\"\\n\\nClusters:\\n\")\n",
    "    for cluster in clusters:\n",
    "        output_result_file.write(str(cluster))\n",
    "        output_result_file.write(\"\\t\")\n",
    "        for tweet in clusters[cluster]:\n",
    "            output_result_file.write(tweet)\n",
    "            output_result_file.write(\", \")\n",
    "        output_result_file.write(\"\\n\")\n",
    "\n",
    "    output_result_file.write(\"\\n\\n\")\n",
    "    output_result_file.write(\"SSE: \")\n",
    "    output_result_file.write(str(sum_squared_error(clusters, centroids, tweets_dict)))\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
